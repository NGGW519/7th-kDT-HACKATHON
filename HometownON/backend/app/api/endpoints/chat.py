from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from pydantic import BaseModel
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.types import RunnableConfig  # ì¶”ê°€
import uuid  # ì¶”ê°€
import logging  # ë””ë²„ê¹…ìš©

from ... import crud
from ...core.database import get_db
from ...chatbot.graph import app  # Import the compiled LangGraph app

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()


class ChatRequest(BaseModel):
    session_id: int | None = None
    message: str


async def event_stream(request: ChatRequest, db: Session, session_id: int = None):
    """Async generator to stream LangGraph response."""
    user_id = None  # Auth tokenì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ

    # 1. session_idê°€ ì´ë¯¸ ì „ë‹¬ëœ ê²½ìš° ì‚¬ìš©, ì•„ë‹ˆë©´ ê¸°ì¡´ ë¡œì§
    if session_id is None:
        session_id = request.session_id
        if session_id:
            chat_session = crud.crud_chat.get_chat_session(db=db, session_id=session_id)
            if not chat_session:
                raise HTTPException(status_code=404, detail="Chat session not found.")
            logger.info(f"ğŸ” Using existing session: {session_id}")
        else:
            chat_session = crud.crud_chat.create_chat_session(db=db, user_id=user_id)
            db.commit()
            session_id = chat_session.id
            logger.info(f"ğŸ†• Created new session: {session_id}")
    else:
        logger.info(f"ğŸ“Œ Using provided session: {session_id}")

    # 2. Save user message to DB
    crud.crud_chat.add_chat_message(
        db=db, session_id=session_id, role="user", content=request.message
    )
    db.flush()
    db.commit()
    logger.info(f"ğŸ’¾ Saved user message to session {session_id}")

    # 3. Fetch full chat history for LangGraph memory
    chat_history = crud.crud_chat.get_chat_messages(db=db, session_id=session_id)
    logger.info(f"ğŸ“š Retrieved {len(chat_history)} messages from DB for session {session_id}")
    
    # ë””ë²„ê¹…: ê° ë©”ì‹œì§€ ë‚´ìš© í™•ì¸
    for i, msg in enumerate(chat_history):
        logger.info(f"   Message {i+1}: {msg.role} - {msg.content[:50]}...")

    formatted_messages = []
    for msg in chat_history:
        if msg.role == "user":
            formatted_messages.append(HumanMessage(content=msg.content))
        elif msg.role == "assistant":
            formatted_messages.append(AIMessage(content=msg.content))
    
    logger.info(f"ğŸ”„ Formatted {len(formatted_messages)} messages for LangGraph")
    
    # ë””ë²„ê¹…: í¬ë§·ëœ ë©”ì‹œì§€ë“¤ í™•ì¸
    for i, msg in enumerate(formatted_messages):
        logger.info(f"   Formatted Message {i+1}: {type(msg).__name__} - {msg.content[:50]}...")

    # 4. Prepare initial state
    initial_state = {
        "prompt": request.message,
        "messages": formatted_messages,
    }
    logger.info(f"ğŸ¯ Initial state prepared with {len(initial_state['messages'])} messages")

    # 5. âœ¨ RunnableConfig ì„¤ì • - ì„¸ì…˜ IDë¥¼ thread_idë¡œ ì‚¬ìš© âœ¨
    thread_id = f"session_{session_id}"  # ë” ëª…í™•í•œ thread_id
    config = RunnableConfig(
        configurable={
            "thread_id": thread_id
        }
    )
    logger.info(f"âš™ï¸ Config created with thread_id: {thread_id}")

    # 6. ì²´í¬í¬ì¸í„° ìƒíƒœ í™•ì¸ ë° ê¸°ì¡´ ìƒíƒœ ë¡œë“œ
    try:
        from ...chatbot.graph import memory
        existing_checkpoints = list(memory.list(config))
        logger.info(f"ğŸ—„ï¸ Found {len(existing_checkpoints)} existing checkpoints for thread {thread_id}")
        
        # ê¸°ì¡´ ìƒíƒœê°€ ìˆë‹¤ë©´ ë¡œë“œí•´ì„œ í™•ì¸
        if existing_checkpoints:
            latest_checkpoint = memory.get(config)
            if latest_checkpoint and latest_checkpoint.checkpoint:
                logger.info(f"ğŸ“– Latest checkpoint has state keys: {list(latest_checkpoint.checkpoint.keys())}")
                if "messages" in latest_checkpoint.checkpoint:
                    checkpoint_messages = latest_checkpoint.checkpoint["messages"]
                    logger.info(f"ğŸ§  Checkpoint contains {len(checkpoint_messages)} messages")
    except Exception as e:
        logger.warning(f"âš ï¸ Could not check existing checkpoints: {e}")

    # 7. LangGraph ìƒíƒœì™€ DB ìƒíƒœ ë¹„êµ
    logger.info(f"ğŸ” State comparison:")
    logger.info(f"   DB messages: {len(formatted_messages)}")
    logger.info(f"   Initial state messages: {len(initial_state['messages'])}")
    logger.info(f"   Current prompt: {request.message[:50]}...")

    # 8. Stream the graph execution with config
    full_response = ""
    event_count = 0
    try:
        logger.info(f"ğŸš€ Starting graph execution...")
        async for event in app.astream(initial_state, config=config):  # config ì¶”ê°€!
            event_count += 1
            logger.info(f"ğŸ“¨ Event {event_count}: {list(event.keys())}")
            
            # ê° ì´ë²¤íŠ¸ì˜ ìƒíƒœë„ ë¡œê¹…
            for node_name, node_data in event.items():
                if "messages" in node_data:
                    logger.info(f"   {node_name} has {len(node_data['messages'])} messages in state")
            
            # ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ì‘ë‹µì„ í™•ì¸
            for agent_name in ["GeneralChatAgent", "AnswerGenerationAgent", "GeneratePostAgent", "GenerateMissionAgent"]:
                if agent_name in event:
                    logger.info(f"ğŸ¤– {agent_name} responded")
                    ai_message = event[agent_name]["messages"][-1]
                    if hasattr(ai_message, "content") and ai_message.content:
                        logger.info(f"ğŸ’¬ {agent_name} content length: {len(ai_message.content)}")
                        # SSE-safe format
                        for char in ai_message.content:
                            yield char
                            full_response += char
                        break  # í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ë§Œ ì²˜ë¦¬
        
        logger.info(f"âœ… Stream completed. Total events: {event_count}, Response length: {len(full_response)}")
                        
    except Exception as e:
        logger.error(f"âŒ Error during graph execution: {e}")
        raise

    # 9. Save AI response to DB
    if full_response:
        crud.crud_chat.add_chat_message(
            db=db, session_id=session_id, role="assistant", content=full_response
        )
        db.commit()
        logger.info(f"ğŸ’¾ Saved AI response to session {session_id}")
        
        # ìµœì¢… í™•ì¸: DBì— ì €ì¥ëœ ì´ ë©”ì‹œì§€ ìˆ˜
        final_count = len(crud.crud_chat.get_chat_messages(db=db, session_id=session_id))
        logger.info(f"ğŸ“Š Final message count in DB for session {session_id}: {final_count}")
    else:
        logger.warning(f"âš ï¸ No response content to save for session {session_id}")


@router.post("/chat")
async def chat_endpoint(request: ChatRequest, db: Session = Depends(get_db)):
    """Chat endpoint that returns session_id in response header"""
    
    # ì„¸ì…˜ ID ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸°/ìƒì„±
    session_id = request.session_id
    if session_id:
        chat_session = crud.crud_chat.get_chat_session(db=db, session_id=session_id)
        if not chat_session:
            raise HTTPException(status_code=404, detail="Chat session not found.")
    else:
        chat_session = crud.crud_chat.create_chat_session(db=db, user_id=None)
        db.commit()
        session_id = chat_session.id
    
    # ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
    async def simple_generator():
        async for chunk in event_stream(request, db, session_id):
            yield chunk
    
    return StreamingResponse(
        simple_generator(), 
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Session-ID": str(session_id)  # í—¤ë”ë¡œ session_id ì „ë‹¬
        }
    )